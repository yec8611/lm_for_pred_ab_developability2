{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
    "                             roc_auc_score, confusion_matrix, ConfusionMatrixDisplay,\n",
    "                             cohen_kappa_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import gc\n",
    "import time\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "ESM2_MODEL_NAMES = [\n",
    "    \"facebook/esm2_t6_8M_UR50D\",\n",
    "    \"facebook/esm2_t12_35M_UR50D\",\n",
    "    \"facebook/esm2_t30_150M_UR50D\",\n",
    "    \"facebook/esm2_t33_650M_UR50D\",\n",
    "]\n",
    "\n",
    "try:\n",
    "    df1 = pd.read_excel('pnas.1616408114.sd01.xlsx')\n",
    "    df2 = pd.read_excel('pnas.1616408114.sd02.xlsx')\n",
    "    df3 = pd.read_excel('pnas.1616408114.sd03.xlsx')\n",
    "    merged_df = df1.merge(df2, on='Name', how='outer').merge(df3, on='Name', how='outer')\n",
    "    df = merged_df[['VH', 'VL', 'Poly-Specificity Reagent (PSR) SMP Score (0-1)']].copy()\n",
    "    df = df.rename(columns={'Poly-Specificity Reagent (PSR) SMP Score (0-1)': 'psr'})\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: One or more Excel files not found. Using a placeholder empty DataFrame.\")\n",
    "    print(\"Please ensure 'pnas.1616408114.sd01.xlsx', 'pnas.1616408114.sd02.xlsx', 'pnas.1616408114.sd03.xlsx' are available.\")\n",
    "    data = {'VH': ['SEQVHONE', 'SEQVHTWO', 'SEQVHTHREE'] * 10,\n",
    "            'VL': ['SEQVLONE', 'SEQVLTWO', 'SEQVLTHREE'] * 10,\n",
    "            'psr': np.random.rand(30) * 0.5\n",
    "           }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "def psr_to_label(psr_value):\n",
    "        if psr_value < 0.10: return 0\n",
    "        elif 0.10 <= psr_value <= 0.33: return 1\n",
    "        else: return 2\n",
    "\n",
    "df['label'] = df['psr'].apply(psr_to_label)\n",
    "print(df.head())\n",
    "\n",
    "label_counts = df['label'].value_counts().sort_index()\n",
    "print(f\"\\nLabel distribution:\\n{label_counts}\")\n",
    "\n",
    "weights_values = np.zeros(NUM_CLASSES)\n",
    "if not label_counts.empty:\n",
    "    for i in range(NUM_CLASSES):\n",
    "        if i in label_counts.index:\n",
    "            weights_values[i] = 1.0 / np.sqrt(label_counts[i])\n",
    "        else:\n",
    "            weights_values[i] = 1.0\n",
    "            print(f\"Warning: Class {i} not found in data for weight calculation. Using default weight 1.0.\")\n",
    "else:\n",
    "    print(\"Warning: Label counts are empty. Using default weights of 1.0 for all classes.\")\n",
    "    weights_values = np.ones(NUM_CLASSES)\n",
    "\n",
    "\n",
    "class_weights_tensor = torch.tensor(weights_values, dtype=torch.float)\n",
    "print(f\"Calculated class weights: {class_weights_tensor.tolist()}\")\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 8\n",
    "NUM_FOLDS = 5\n",
    "SEED = 42\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "EPOCHS = 10\n",
    "EARLY_STOPPING_PATIENCE = 3\n",
    "LR_SCHEDULER_PATIENCE = 1\n",
    "\n",
    "class AntibodyPsrDataset(Dataset):\n",
    "    def __init__(self, vh_sequences, vl_sequences, targets, tokenizer, max_len):\n",
    "        self.vh_sequences = vh_sequences\n",
    "        self.vl_sequences = vl_sequences\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vh_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vh_seq = str(self.vh_sequences[idx])\n",
    "        vl_seq = str(self.vl_sequences[idx])\n",
    "        target = int(self.targets[idx])\n",
    "\n",
    "        combined_sequence = vh_seq + 'X' + vl_seq\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            combined_sequence, add_special_tokens=True, max_length=self.max_len,\n",
    "            return_token_type_ids=False, padding='max_length', truncation=True,\n",
    "            return_attention_mask=True, return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(target, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def create_simple_classifier(input_size, num_classes):\n",
    "    return nn.Linear(input_size, num_classes)\n",
    "\n",
    "def create_medium_mlp_classifier(input_size, num_classes, hidden_dim=256):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_dim),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm1d(hidden_dim),\n",
    "        nn.Dropout(0.30),\n",
    "        nn.Linear(hidden_dim, num_classes)\n",
    "    )\n",
    "\n",
    "def create_deep_mlp_classifier(input_size, num_classes, hidden_dims=[512, 256, 128]):\n",
    "    layers = []\n",
    "    current_dim = input_size\n",
    "    for h_dim in hidden_dims:\n",
    "        layers.append(nn.Linear(current_dim, h_dim))\n",
    "        layers.append(nn.GELU())\n",
    "        layers.append(nn.BatchNorm1d(h_dim))\n",
    "        layers.append(nn.Dropout(0.30))\n",
    "        current_dim = h_dim\n",
    "    layers.append(nn.Linear(current_dim, num_classes))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.attention_scorer = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        scores = self.attention_scorer(last_hidden_state)\n",
    "        scores = scores.squeeze(-1)\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            scores = scores.masked_fill(attention_mask == 0, -float('inf'))\n",
    "            \n",
    "        weights = nn.functional.softmax(scores, dim=1)\n",
    "        weights = weights.unsqueeze(-1)\n",
    "        \n",
    "        pooled_output = torch.sum(weights * last_hidden_state, dim=1)\n",
    "        return pooled_output\n",
    "\n",
    "class EsmForAntibodyPsrClassification(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, head_type='medium'):\n",
    "        super().__init__()\n",
    "        print(f\"Loading base ESM model: {model_name}\")\n",
    "        self.esm_model = AutoModel.from_pretrained(model_name)\n",
    "        hidden_size = self.esm_model.config.hidden_size\n",
    "        \n",
    "        print(\"Initializing Attention Pooling layer...\")\n",
    "        self.pooler = AttentionPooling(hidden_size)\n",
    "\n",
    "        print(\"Freezing base ESM model parameters...\")\n",
    "        for param in self.esm_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        classifier_input_size = hidden_size\n",
    "        print(f\"Creating classification head of type: {head_type} with input size {classifier_input_size}\")\n",
    "        if head_type == 'simple':\n",
    "            self.classifier = create_simple_classifier(classifier_input_size, num_classes)\n",
    "        elif head_type == 'medium':\n",
    "            self.classifier = create_medium_mlp_classifier(classifier_input_size, num_classes)\n",
    "        elif head_type == 'deep':\n",
    "            self.classifier = create_deep_mlp_classifier(classifier_input_size, num_classes)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid head_type. Choose 'simple', 'medium', or 'deep'.\")\n",
    "        print(\"Model initialization complete.\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.esm_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        \n",
    "        pooled_output = self.pooler(last_hidden_state, attention_mask)\n",
    "        \n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "def initialize_model_and_optimizer(model_name, num_classes, head_type, learning_rate, weight_decay, class_weights_tensor):\n",
    "    model = EsmForAntibodyPsrClassification(model_name, num_classes, head_type=head_type)\n",
    "    model.to(device)\n",
    "    \n",
    "    trainable_params = list(model.pooler.parameters()) + list(model.classifier.parameters())\n",
    "\n",
    "    optimizer = optim.AdamW(\n",
    "        trainable_params,\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    print(\"\\nOptimizer initialized. Training parameters (attention pooler + classification head):\")\n",
    "    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters: {num_trainable}\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor.to(device) if class_weights_tensor is not None else None)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=LR_SCHEDULER_PATIENCE, verbose=True)\n",
    "    \n",
    "    return model, optimizer, criterion, scheduler\n",
    "\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"  Train Epoch completed in {elapsed_time:.2f}s, Avg. Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device, num_classes):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_labels, all_predictions, all_probabilities = [], [], []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            predictions = torch.argmax(probabilities, dim=1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    all_labels, all_predictions, all_probabilities = np.array(all_labels), np.array(all_predictions), np.array(all_probabilities)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision_w, recall_w, f1_w, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(all_labels, all_predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    cohen_k = float('nan')\n",
    "    if len(np.unique(all_labels)) >= 2:\n",
    "        cohen_k = cohen_kappa_score(all_labels, all_predictions, weights='quadratic')\n",
    "    else:\n",
    "        print(\"  Info: Cohen's Kappa N/A (fewer than 2 classes in this fold's validation labels).\")\n",
    "\n",
    "    roc_auc = float('nan')\n",
    "    unique_labels_in_fold = np.unique(all_labels)\n",
    "    if len(unique_labels_in_fold) == num_classes and num_classes > 1:\n",
    "        try:\n",
    "            if num_classes == 2:\n",
    "                 roc_auc = roc_auc_score(all_labels, all_probabilities[:, 1])\n",
    "            else:\n",
    "                 roc_auc = roc_auc_score(all_labels, all_probabilities, multi_class='ovr', average='weighted', labels=list(range(num_classes)))\n",
    "        except ValueError as e: \n",
    "            print(f\"  Warning: ROC AUC calculation failed: {e}\")\n",
    "            if len(unique_labels_in_fold) < num_classes:\n",
    "                 print(f\"  Info: ROC AUC N/A (only {len(unique_labels_in_fold)}/{num_classes} classes present in this fold's validation set).\")\n",
    "    elif num_classes == 1:\n",
    "        print(\" Info: ROC AUC N/A (only 1 class defined).\")\n",
    "    else:\n",
    "        print(f\"  Info: ROC AUC N/A (only {len(unique_labels_in_fold)}/{num_classes} classes present in this fold's validation set).\")\n",
    "        \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"  Evaluation completed in {elapsed_time:.2f}s\")\n",
    "    return avg_loss, accuracy, precision_w, recall_w, f1_w, f1_macro, cohen_k, roc_auc, all_labels, all_predictions\n",
    "\n",
    "def run_training_fold(current_esm_model_name, model_obj, optimizer, criterion, scheduler, train_loader, val_loader, epochs, device, num_classes, fold_num):\n",
    "    best_val_f1_weighted = -1.0\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    train_losses, val_losses, metrics_history = [], [], []\n",
    "    \n",
    "    print(f\"Starting training for Fold {fold_num} (ESM Model: {current_esm_model_name}), max {epochs} epochs...\")\n",
    "    total_fold_start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        print(f\"\\n-- Epoch {epoch+1}/{epochs} -- Current LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        avg_train_loss = train_epoch(model_obj, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        avg_val_loss, val_accuracy, _, _, val_f1_w, val_f1_macro, val_cohen_k, val_roc_auc, _, _ = evaluate_model(\n",
    "            model_obj, val_loader, criterion, device, num_classes\n",
    "        )\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        metrics_history.append({\n",
    "            'epoch': epoch + 1, 'train_loss': avg_train_loss, 'val_loss': avg_val_loss,\n",
    "            'val_accuracy': val_accuracy, 'val_f1_weighted': val_f1_w, \n",
    "            'val_f1_macro': val_f1_macro, 'val_cohen_kappa': val_cohen_k, 'val_roc_auc': val_roc_auc\n",
    "        })\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f\"Epoch {epoch+1} Summary | Time: {epoch_time:.2f}s\")\n",
    "        print(f\"  Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f} | Val F1 (w): {val_f1_w:.4f} | Val F1 (m): {val_f1_macro:.4f} | Val Kappa: {val_cohen_k:.4f} | Val AUC: {val_roc_auc:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_f1_w)\n",
    "\n",
    "        if val_f1_w > best_val_f1_weighted:\n",
    "            best_val_f1_weighted = val_f1_w\n",
    "            best_model_state = copy.deepcopy(model_obj.state_dict())\n",
    "            epochs_no_improve = 0\n",
    "            print(f\"  -> New best validation F1 (weighted): {best_val_f1_weighted:.4f}. Saving model state.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  Validation F1 (weighted) did not improve for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "            \n",
    "        if device == torch.device(\"mps\"): torch.mps.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    total_fold_time = time.time() - total_fold_start_time\n",
    "    print(f\"\\nTraining finished for Fold {fold_num}. Total time: {total_fold_time:.2f}s. Best F1 (w): {best_val_f1_weighted:.4f}\")\n",
    "    return best_model_state, train_losses, val_losses, metrics_history, best_val_f1_weighted\n",
    "\n",
    "if df.empty or len(df) < NUM_FOLDS:\n",
    "    print(\"DataFrame is empty or has insufficient data for K-Fold cross-validation. Exiting.\")\n",
    "else:\n",
    "    all_vh_sequences = df['VH'].tolist()\n",
    "    all_vl_sequences = df['VL'].tolist()\n",
    "    all_labels_list = df['label'].tolist()\n",
    "    overall_results_per_esm_model = []\n",
    "\n",
    "    for esm_model_name_hf in ESM2_MODEL_NAMES:\n",
    "        print(f\"\\n\\n===== Processing ESM Model: {esm_model_name_hf} =====\")\n",
    "        \n",
    "        current_head_type = 'medium'\n",
    "        if \"8M\" in esm_model_name_hf: current_head_type = 'simple'\n",
    "        elif \"35M\" in esm_model_name_hf or \"150M\" in esm_model_name_hf: current_head_type = 'medium'\n",
    "        elif \"650M\" in esm_model_name_hf: current_head_type = 'deep'\n",
    "        print(f\"Using head type: {current_head_type} for {esm_model_name_hf}\")\n",
    "\n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(esm_model_name_hf)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load tokenizer for {esm_model_name_hf}, trying base. Error: {e}\")\n",
    "            try: tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "            except Exception as e_base:\n",
    "                print(f\"Could not load base ESM tokenizer. Error: {e_base}. Skipping this model.\")\n",
    "                overall_results_per_esm_model.append({'ESM Model': esm_model_name_hf, 'Error': f'Tokenizer load failed: {e_base}'})\n",
    "                continue\n",
    "\n",
    "        full_dataset = AntibodyPsrDataset(all_vh_sequences, all_vl_sequences, all_labels_list, tokenizer, MAX_LENGTH)\n",
    "        if len(full_dataset) < NUM_FOLDS:\n",
    "            print(f\"Skipping {esm_model_name_hf}: Not enough samples ({len(full_dataset)}) for {NUM_FOLDS}-fold cross-validation.\")\n",
    "            overall_results_per_esm_model.append({'ESM Model': esm_model_name_hf, 'Error': 'Insufficient samples for CV'})\n",
    "            continue\n",
    "\n",
    "        kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "        fold_results_current_esm = []\n",
    "        \n",
    "        print(f\"\\n--- Starting {NUM_FOLDS}-Fold Cross-Validation for {esm_model_name_hf} ---\")\n",
    "        cv_start_time = time.time()\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(all_vh_sequences)):\n",
    "            fold_num = fold + 1\n",
    "            print(f\"\\n==================== Fold {fold_num}/{NUM_FOLDS} ({esm_model_name_hf}) ====================\")\n",
    "            \n",
    "            if len(val_idx) == 0 or len(train_idx) == 0:\n",
    "                print(f\"Skipping Fold {fold_num} due to empty train/validation set from KFold split.\")\n",
    "                continue\n",
    "\n",
    "            train_sampler = SubsetRandomSampler(train_idx)\n",
    "            val_sampler = SubsetRandomSampler(val_idx)\n",
    "            \n",
    "            train_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=0, pin_memory=True if device.type != 'mps' else False)\n",
    "            val_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, num_workers=0, pin_memory=True if device.type != 'mps' else False)\n",
    "            print(f\"Fold {fold_num}: Train samples = {len(train_idx)}, Validation samples = {len(val_idx)}\")\n",
    "\n",
    "            current_batch_size_to_check = BATCH_SIZE\n",
    "            if \"650M\" in esm_model_name_hf and current_batch_size_to_check > 1 and device == torch.device(\"mps\"):\n",
    "                print(f\"Warning: BATCH_SIZE {current_batch_size_to_check} might be too large for {esm_model_name_hf} (650M) on MPS. Consider reducing to 1.\")\n",
    "            elif \"150M\" in esm_model_name_hf and current_batch_size_to_check > 2 and device == torch.device(\"mps\"):\n",
    "                print(f\"Warning: BATCH_SIZE {current_batch_size_to_check} might be too large for {esm_model_name_hf} (150M) on MPS. Consider reducing to 1-2.\")\n",
    "            elif \"35M\" in esm_model_name_hf and current_batch_size_to_check > 4 and device == torch.device(\"mps\"):\n",
    "                print(f\"Warning: BATCH_SIZE {current_batch_size_to_check} might be too large for {esm_model_name_hf} (35M) on MPS. Consider reducing.\")\n",
    "\n",
    "            model, optimizer, criterion, scheduler = initialize_model_and_optimizer(\n",
    "                esm_model_name_hf, NUM_CLASSES, current_head_type, LEARNING_RATE, WEIGHT_DECAY, class_weights_tensor\n",
    "            )\n",
    "            best_model_state, train_losses, val_losses, metrics_history, fold_best_f1_w = run_training_fold(\n",
    "                esm_model_name_hf, model, optimizer, criterion, scheduler, train_loader, val_loader, EPOCHS, device, NUM_CLASSES, fold_num\n",
    "            )\n",
    "            if best_model_state:\n",
    "                model.load_state_dict(best_model_state)\n",
    "                print(\"\\nLoaded best model state from training for final evaluation on this fold.\")\n",
    "            else:\n",
    "                print(\"\\nWarning: No best model state saved (e.g., training too short or no improvement). Evaluating last state.\")\n",
    "            \n",
    "            print(f\"Performing final evaluation for Fold {fold_num} ({esm_model_name_hf}) using best F1 model...\")\n",
    "            final_val_loss, final_accuracy, final_prec_w, final_recall_w, final_f1_w, final_f1_macro, final_cohen_k, final_roc_auc, fold_labels, fold_preds = evaluate_model(\n",
    "                model, val_loader, criterion, device, NUM_CLASSES\n",
    "            )\n",
    "            print(f\"\\nFold {fold_num} ({esm_model_name_hf}) Final Validation Metrics (Best F1 Model):\")\n",
    "            print(f\"  Loss:           {final_val_loss:.4f}\")\n",
    "            print(f\"  Accuracy:       {final_accuracy:.4f}\")\n",
    "            print(f\"  Precision (w):  {final_prec_w:.4f}\")\n",
    "            print(f\"  Recall (w):     {final_recall_w:.4f}\")\n",
    "            print(f\"  F1 Score (w):   {final_f1_w:.4f}\")\n",
    "            print(f\"  F1 Score (m):   {final_f1_macro:.4f}\")\n",
    "            print(f\"  Cohen's Kappa:  {final_cohen_k:.4f}\")\n",
    "            print(f\"  ROC AUC (w ovr):{final_roc_auc:.4f}\")\n",
    "            \n",
    "            fold_results_current_esm.append({\n",
    "                'fold': fold_num, 'accuracy': final_accuracy, 'precision_w': final_prec_w,\n",
    "                'recall_w': final_recall_w, 'f1_w': final_f1_w, 'f1_macro': final_f1_macro,\n",
    "                'cohen_kappa': final_cohen_k, 'roc_auc': final_roc_auc, 'best_val_metric_f1w': fold_best_f1_w,\n",
    "            })\n",
    "            \n",
    "            if metrics_history:\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.plot([m['epoch'] for m in metrics_history], [m['train_loss'] for m in metrics_history], label='Training Loss', marker='o')\n",
    "                plt.plot([m['epoch'] for m in metrics_history], [m['val_loss'] for m in metrics_history], label='Validation Loss', marker='x')\n",
    "                plt.xlabel('Epoch'); plt.ylabel('Loss (CrossEntropy)'); plt.title(f'Fold {fold_num} ({esm_model_name_hf}) - Loss')\n",
    "                plt.legend(); plt.grid(True); plt.ylim(bottom=0)\n",
    "\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.plot([m['epoch'] for m in metrics_history], [m['val_f1_weighted'] for m in metrics_history], label='Val F1 (w)', marker='s')\n",
    "                plt.plot([m['epoch'] for m in metrics_history], [m['val_f1_macro'] for m in metrics_history], label='Val F1 (m)', marker='p')\n",
    "                valid_roc_auc = [m['val_roc_auc'] for m in metrics_history if not np.isnan(m['val_roc_auc'])]\n",
    "                if valid_roc_auc:\n",
    "                    plt.plot([m['epoch'] for m in metrics_history if not np.isnan(m['val_roc_auc'])], valid_roc_auc, label='Val ROC AUC', marker='^')\n",
    "                plt.plot([m['epoch'] for m in metrics_history], [m['val_accuracy'] for m in metrics_history], label='Val Accuracy', marker='.')\n",
    "                plt.xlabel('Epoch'); plt.ylabel('Metric Value'); plt.title(f'Fold {fold_num} ({esm_model_name_hf}) - Metrics')\n",
    "                plt.legend(); plt.grid(True); plt.ylim(0, 1.05)\n",
    "                plt.tight_layout(); plt.show()\n",
    "            else:\n",
    "                print(f\"No metrics history recorded for Fold {fold_num} to plot.\")\n",
    "\n",
    "\n",
    "            if len(fold_labels) > 0 and len(fold_preds) > 0:\n",
    "                try:\n",
    "                    cm = confusion_matrix(fold_labels, fold_preds, labels=list(range(NUM_CLASSES)))\n",
    "                    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[f'Class {i}' for i in range(NUM_CLASSES)])\n",
    "                    disp.plot(cmap=plt.cm.Blues)\n",
    "                    plt.title(f'Fold {fold_num} ({esm_model_name_hf}) - Confusion Matrix')\n",
    "                    plt.show()\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not display confusion matrix for Fold {fold_num}: {e}\")\n",
    "            else:\n",
    "                print(f\"Not enough data to generate confusion matrix for Fold {fold_num}.\")\n",
    "\n",
    "\n",
    "            print(f\"Cleaning up Fold {fold_num} resources...\")\n",
    "            del model, optimizer, criterion, scheduler, train_loader, val_loader, train_sampler, val_sampler, best_model_state\n",
    "            if device == torch.device(\"mps\"): torch.mps.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        cv_end_time = time.time()\n",
    "        print(f\"\\n--- Cross-Validation Finished for {esm_model_name_hf} --- Total Time: {cv_end_time - cv_start_time:.2f}s ---\")\n",
    "        \n",
    "        results_df_current_esm = pd.DataFrame(fold_results_current_esm)\n",
    "        avg_metrics_dict = {'ESM Model': esm_model_name_hf, 'Error': None}\n",
    "        if not results_df_current_esm.empty:\n",
    "            print(f\"\\n--- Cross-Validation Summary for {esm_model_name_hf} ---\")\n",
    "            metric_cols = ['fold', 'accuracy', 'f1_w', 'f1_macro', 'cohen_kappa', 'roc_auc', 'best_val_metric_f1w']\n",
    "            print(results_df_current_esm[metric_cols].round(4).to_string(index=False))\n",
    "            \n",
    "            for metric in ['accuracy', 'f1_w', 'f1_macro', 'cohen_kappa', 'roc_auc']:\n",
    "                avg_metrics_dict[f'Avg {metric}'] = results_df_current_esm[metric].mean()\n",
    "                avg_metrics_dict[f'Std {metric}'] = results_df_current_esm[metric].std()\n",
    "        else:\n",
    "            avg_metrics_dict['Error'] = 'No fold results to aggregate (e.g. all folds skipped)'\n",
    "\n",
    "        overall_results_per_esm_model.append(avg_metrics_dict)\n",
    "        print(\"\\nAverage Metrics Across Folds:\")\n",
    "        for key, val in avg_metrics_dict.items():\n",
    "            if key not in ['ESM Model', 'Error'] and \"Std\" not in key:\n",
    "                std_key = key.replace(\"Avg\", \"Std\")\n",
    "                if isinstance(val, (int, float)) and not np.isnan(val):\n",
    "                     print(f\"  {key:<20}: {val:.4f} +/- {avg_metrics_dict.get(std_key, 0.0):.4f}\")\n",
    "                else:\n",
    "                     print(f\"  {key:<20}: N/A\")\n",
    "\n",
    "            elif key == 'Error' and val is not None:\n",
    "                print(f\"  Error: {val}\")\n",
    "\n",
    "    print(\"\\n\\n===== Overall Summary Across All ESM Models =====\")\n",
    "    summary_df = pd.DataFrame(overall_results_per_esm_model)\n",
    "    cols_to_display = ['ESM Model', 'Error']\n",
    "    if any(r.get('Error') is None for r in overall_results_per_esm_model):\n",
    "        first_valid_result = next((r for r in overall_results_per_esm_model if r.get('Error') is None), None)\n",
    "        if first_valid_result:\n",
    "            metric_avg_std_cols = [k for k in first_valid_result.keys() if k not in ['ESM Model', 'Error']]\n",
    "            cols_to_display.extend(metric_avg_std_cols)\n",
    "\n",
    "    summary_df_display = summary_df[[col for col in cols_to_display if col in summary_df.columns]]\n",
    "    numeric_cols = summary_df_display.select_dtypes(include=np.number).columns\n",
    "    summary_df_display[numeric_cols] = summary_df_display[numeric_cols].round(4)\n",
    "    print(summary_df_display.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
