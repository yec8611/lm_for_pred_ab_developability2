{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
    "                             roc_auc_score, confusion_matrix, ConfusionMatrixDisplay,\n",
    "                             cohen_kappa_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import gc\n",
    "import time\n",
    "import re\n",
    "\n",
    "try:\n",
    "    from peft import LoraConfig, get_peft_model, PeftModel\n",
    "    PEFT_AVAILABLE = True\n",
    "    print(\"PEFT library loaded successfully.\")\n",
    "except ImportError:\n",
    "    PEFT_AVAILABLE = False\n",
    "    print(\"PEFT library not found. LoRA fine-tuning will not be available.\")\n",
    "    print(\"Please install PEFT: pip install peft\")\n",
    "\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "ESM2_MODEL_NAMES = [\n",
    "    \"facebook/esm2_t6_8M_UR50D\",\n",
    "    \"facebook/esm2_t12_35M_UR50D\",\n",
    "    \"facebook/esm2_t30_150M_UR50D\",\n",
    "    \"facebook/esm2_t33_650M_UR50D\",\n",
    "]\n",
    "\n",
    "try:\n",
    "    df1 = pd.read_excel('pnas.1616408114.sd01.xlsx')\n",
    "    df2 = pd.read_excel('pnas.1616408114.sd02.xlsx')\n",
    "    df3 = pd.read_excel('pnas.1616408114.sd03.xlsx')\n",
    "    merged_df = df1.merge(df2, on='Name', how='outer').merge(df3, on='Name', how='outer')\n",
    "    df = merged_df[['VH', 'VL', 'Poly-Specificity Reagent (PSR) SMP Score (0-1)']].copy()\n",
    "    df = df.rename(columns={'Poly-Specificity Reagent (PSR) SMP Score (0-1)': 'psr'})\n",
    "    print(\"Successfully loaded and merged Excel files.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: One or more Excel files not found. Using a placeholder empty DataFrame.\")\n",
    "    print(\"Please ensure 'pnas.1616408114.sd01.xlsx', 'pnas.1616408114.sd02.xlsx', 'pnas.1616408114.sd03.xlsx' are available.\")\n",
    "    data = {'Name': [f'ID_{i}' for i in range(30)],\n",
    "            'VH': ['SEQVHONEAA'* (10+i%3) for i in range(30)],\n",
    "            'VL': ['SEQVLONEBB'* (10+i%2) for i in range(30)],\n",
    "            'Poly-Specificity Reagent (PSR) SMP Score (0-1)': [np.random.rand() * 0.5 + (i%3)*0.2 for i in range(30)]\n",
    "           }\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.rename(columns={'Poly-Specificity Reagent (PSR) SMP Score (0-1)': 'psr'})\n",
    "    print(\"Using dummy data for demonstration.\")\n",
    "\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "def psr_to_label(psr_value):\n",
    "        if psr_value < 0.10: return 0\n",
    "        elif 0.10 <= psr_value <= 0.33: return 1\n",
    "        else: return 2\n",
    "\n",
    "df['label'] = df['psr'].apply(psr_to_label)\n",
    "print(\"\\nDataFrame head after adding labels:\")\n",
    "print(df.head())\n",
    "\n",
    "label_counts = df['label'].value_counts().sort_index()\n",
    "print(f\"\\nLabel distribution:\\n{label_counts}\")\n",
    "\n",
    "weights_values = np.zeros(NUM_CLASSES)\n",
    "if not label_counts.empty:\n",
    "    for i in range(NUM_CLASSES):\n",
    "        if i in label_counts.index:\n",
    "            weights_values[i] = 1.0 / np.sqrt(label_counts[i]) if label_counts[i] > 0 else 1.0\n",
    "        else:\n",
    "            weights_values[i] = 1.0\n",
    "            print(f\"Warning: Class {i} not found in data for weight calculation. Using default weight 1.0.\")\n",
    "else:\n",
    "    print(\"Warning: Label counts are empty. Using default weights of 1.0 for all classes.\")\n",
    "    weights_values = np.ones(NUM_CLASSES)\n",
    "\n",
    "class_weights_tensor = torch.tensor(weights_values, dtype=torch.float)\n",
    "print(f\"Calculated class weights: {class_weights_tensor.tolist()}\")\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 8\n",
    "NUM_FOLDS = 5\n",
    "SEED = 42\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "EPOCHS = 10\n",
    "EARLY_STOPPING_PATIENCE = 3\n",
    "LR_SCHEDULER_PATIENCE = 1\n",
    "\n",
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT = 0.05\n",
    "N_LAST_LAYERS = 3\n",
    "\n",
    "class AntibodyPsrDataset(Dataset):\n",
    "    def __init__(self, vh_sequences, vl_sequences, targets, tokenizer, max_len):\n",
    "        self.vh_sequences = vh_sequences\n",
    "        self.vl_sequences = vl_sequences\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vh_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vh_seq = str(self.vh_sequences[idx])\n",
    "        vl_seq = str(self.vl_sequences[idx])\n",
    "        target = int(self.targets[idx])\n",
    "        combined_sequence = vh_seq + 'X' + vl_seq\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            combined_sequence, add_special_tokens=True, max_length=self.max_len,\n",
    "            return_token_type_ids=False, padding='max_length', truncation=True,\n",
    "            return_attention_mask=True, return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(target, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def create_simple_classifier(input_size, num_classes):\n",
    "    return nn.Linear(input_size, num_classes)\n",
    "\n",
    "def create_medium_mlp_classifier(input_size, num_classes, hidden_dim=256):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_dim),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm1d(hidden_dim),\n",
    "        nn.Dropout(0.30),\n",
    "        nn.Linear(hidden_dim, num_classes)\n",
    "    )\n",
    "\n",
    "def create_deep_mlp_classifier(input_size, num_classes, hidden_dims=[512, 256, 128]):\n",
    "    layers = []\n",
    "    current_dim = input_size\n",
    "    for h_dim in hidden_dims:\n",
    "        layers.append(nn.Linear(current_dim, h_dim))\n",
    "        layers.append(nn.GELU())\n",
    "        layers.append(nn.BatchNorm1d(h_dim))\n",
    "        layers.append(nn.Dropout(0.30))\n",
    "        current_dim = h_dim\n",
    "    layers.append(nn.Linear(current_dim, num_classes))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.attention_scorer = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        scores = self.attention_scorer(last_hidden_state).squeeze(-1)\n",
    "        if attention_mask is not None:\n",
    "            scores = scores.masked_fill(attention_mask == 0, -1e9)\n",
    "        weights = nn.functional.softmax(scores, dim=1).unsqueeze(-1)\n",
    "        pooled_output = torch.sum(weights * last_hidden_state, dim=1)\n",
    "        return pooled_output\n",
    "\n",
    "class EsmForAntibodyPsrClassification(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, head_type='medium',\n",
    "                 lora_r=8, lora_alpha=16, lora_dropout=0.05, n_last_layers=3):\n",
    "        super().__init__()\n",
    "        if not PEFT_AVAILABLE:\n",
    "            raise ImportError(\"PEFT library is not installed. Cannot use LoRA.\")\n",
    "\n",
    "        print(f\"Loading base ESM model: {model_name}\")\n",
    "        self.esm_model_base = AutoModel.from_pretrained(model_name)\n",
    "        hidden_size = self.esm_model_base.config.hidden_size\n",
    "\n",
    "        print(f\"Applying LoRA to the last {n_last_layers} layers of {model_name}\")\n",
    "        print(f\"LoRA R={lora_r}, Alpha={lora_alpha}, Dropout={lora_dropout}\")\n",
    "\n",
    "        target_modules_set = set()\n",
    "        if hasattr(self.esm_model_base.config, 'num_hidden_layers'):\n",
    "            esm_num_layers = self.esm_model_base.config.num_hidden_layers\n",
    "            lora_target_pattern = re.compile(rf\"encoder\\.layer\\.(\\d+)\\.attention\\.self\\.(query|key|value)\")\n",
    "\n",
    "            for name, module in self.esm_model_base.named_modules():\n",
    "                match = lora_target_pattern.match(name)\n",
    "                if match:\n",
    "                    layer_idx = int(match.group(1))\n",
    "                    module_type = match.group(2)\n",
    "                    if layer_idx >= esm_num_layers - n_last_layers:\n",
    "                        target_modules_set.add(module_type)\n",
    "            \n",
    "            if not target_modules_set:\n",
    "                 print(f\"Warning: Could not automatically find target_modules (query, key, value) for LoRA in {model_name} for the last {n_last_layers} layers. LoRA might not be applied correctly. Using default ['query', 'key', 'value'].\")\n",
    "                 target_modules_list = ['query', 'key', 'value']\n",
    "            else:\n",
    "                target_modules_list = list(target_modules_set)\n",
    "            print(f\"Identified LoRA target modules: {target_modules_list}\")\n",
    "        else:\n",
    "            print(f\"Warning: `num_hidden_layers` not found in {model_name} config. Using default target_modules for LoRA: ['query', 'key', 'value'].\")\n",
    "            target_modules_list = ['query', 'key', 'value']\n",
    "\n",
    "        lora_config = LoraConfig(\n",
    "            r=lora_r,\n",
    "            lora_alpha=lora_alpha,\n",
    "            target_modules=target_modules_list,\n",
    "            bias=\"none\",\n",
    "            lora_dropout=lora_dropout,\n",
    "        )\n",
    "        \n",
    "        self.esm_model = get_peft_model(self.esm_model_base, lora_config)\n",
    "        print(\"LoRA applied to ESM model.\")\n",
    "        self.esm_model.print_trainable_parameters()\n",
    "\n",
    "        print(\"Initializing Attention Pooling layer...\")\n",
    "        self.pooler = AttentionPooling(hidden_size)\n",
    "        \n",
    "        classifier_input_size = hidden_size\n",
    "        print(f\"Creating classification head of type: {head_type} with input size {classifier_input_size}\")\n",
    "        if head_type == 'simple':\n",
    "            self.classifier = create_simple_classifier(classifier_input_size, num_classes)\n",
    "        elif head_type == 'medium':\n",
    "            self.classifier = create_medium_mlp_classifier(classifier_input_size, num_classes)\n",
    "        elif head_type == 'deep':\n",
    "            self.classifier = create_deep_mlp_classifier(classifier_input_size, num_classes)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid head_type. Choose 'simple', 'medium', or 'deep'.\")\n",
    "        \n",
    "        print(\"Model initialization complete.\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.esm_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        if hasattr(outputs, 'last_hidden_state'):\n",
    "            last_hidden_state = outputs.last_hidden_state\n",
    "        elif isinstance(outputs, torch.Tensor):\n",
    "            print(\"Warning: ESM model output is a tensor, not a dict. Assuming it's last_hidden_state.\")\n",
    "            last_hidden_state = outputs\n",
    "        else:\n",
    "            print(\"Warning: ESM model output is a tuple. Assuming first element is last_hidden_state.\")\n",
    "            last_hidden_state = outputs[0]\n",
    "\n",
    "        pooled_output = self.pooler(last_hidden_state, attention_mask)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "def initialize_model_and_optimizer(model_name, num_classes, head_type, learning_rate, weight_decay, class_weights_tensor,\n",
    "                                   lora_r, lora_alpha, lora_dropout, n_last_layers):\n",
    "    model = EsmForAntibodyPsrClassification(\n",
    "        model_name, num_classes, head_type=head_type,\n",
    "        lora_r=lora_r, lora_alpha=lora_alpha, lora_dropout=lora_dropout, n_last_layers=n_last_layers\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    print(\"\\nOptimizer initialized.\")\n",
    "    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters (LoRA adapters + Pooler + Classifier): {num_trainable}\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor.to(device) if class_weights_tensor is not None else None)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=LR_SCHEDULER_PATIENCE, verbose=True)\n",
    "    \n",
    "    return model, optimizer, criterion, scheduler\n",
    "\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
    "    model.train() \n",
    "    total_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(data_loader) if len(data_loader) > 0 else 0\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"  Train Epoch completed in {elapsed_time:.2f}s, Avg. Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device, num_classes):\n",
    "    model.eval() \n",
    "    total_loss = 0.0\n",
    "    all_labels, all_predictions, all_probabilities = [], [], []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            predictions = torch.argmax(probabilities, dim=1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            \n",
    "    avg_loss = total_loss / len(data_loader) if len(data_loader) > 0 else 0\n",
    "    all_labels_np, all_predictions_np = np.array(all_labels), np.array(all_predictions)\n",
    "    all_probabilities_np = np.array(all_probabilities)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels_np, all_predictions_np) if len(all_labels_np) > 0 else 0.0\n",
    "    precision_w, recall_w, f1_w, _ = precision_recall_fscore_support(all_labels_np, all_predictions_np, average='weighted', zero_division=0) if len(all_labels_np) > 0 else (0.0,0.0,0.0,None)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(all_labels_np, all_predictions_np, average='macro', zero_division=0) if len(all_labels_np) > 0 else (0.0,0.0,0.0,None)\n",
    "    \n",
    "    cohen_k = float('nan')\n",
    "    if len(all_labels_np) > 0 and len(np.unique(all_labels_np)) >= 2:\n",
    "        cohen_k = cohen_kappa_score(all_labels_np, all_predictions_np, weights='quadratic')\n",
    "    else:\n",
    "        print(\"  Info: Cohen's Kappa N/A (fewer than 2 unique classes or no labels in this fold's validation).\")\n",
    "\n",
    "    roc_auc = float('nan')\n",
    "    if len(all_labels_np) > 0:\n",
    "        unique_labels_in_fold = np.unique(all_labels_np)\n",
    "        probs_for_roc = all_probabilities_np\n",
    "\n",
    "        if len(unique_labels_in_fold) == num_classes and num_classes > 1 :\n",
    "            try:\n",
    "                if num_classes == 2:\n",
    "                    roc_auc_probs = probs_for_roc[:, 1] if probs_for_roc.ndim > 1 and probs_for_roc.shape[1] == 2 else probs_for_roc\n",
    "                    roc_auc = roc_auc_score(all_labels_np, roc_auc_probs)\n",
    "                else:\n",
    "                    roc_auc = roc_auc_score(all_labels_np, probs_for_roc, multi_class='ovr', average='weighted', labels=list(range(num_classes)))\n",
    "            except ValueError as e:\n",
    "                print(f\"  Warning: ROC AUC calculation failed: {e}\")\n",
    "        elif num_classes <= 1:\n",
    "            print(\"  Info: ROC AUC N/A (<=1 class defined).\")\n",
    "        else:\n",
    "            print(f\"  Info: ROC AUC N/A (only {len(unique_labels_in_fold)}/{num_classes} classes present, or other issue).\")\n",
    "    else:\n",
    "        print(\"  Info: ROC AUC N/A (no labels in validation set).\")\n",
    "        \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"  Evaluation completed in {elapsed_time:.2f}s\")\n",
    "    return avg_loss, accuracy, precision_w, recall_w, f1_w, f1_macro, cohen_k, roc_auc, all_labels_np, all_predictions_np\n",
    "\n",
    "def run_training_fold(current_esm_model_name, model_obj, optimizer, criterion, scheduler, train_loader, val_loader, epochs, device, num_classes, fold_num):\n",
    "    best_val_f1_weighted = -1.0\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    train_losses, val_losses, metrics_history = [], [], []\n",
    "    \n",
    "    print(f\"Starting training for Fold {fold_num} (ESM Model: {current_esm_model_name}), LoRA fine-tuning, max {epochs} epochs...\")\n",
    "    total_fold_start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        current_lr = optimizer.param_groups[0]['lr'] if optimizer.param_groups else LEARNING_RATE\n",
    "        print(f\"\\n-- Epoch {epoch+1}/{epochs} -- Current LR: {current_lr:.2e}\")\n",
    "        \n",
    "        avg_train_loss = train_epoch(model_obj, train_loader, criterion, optimizer, device)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        avg_val_loss, val_accuracy, _, _, val_f1_w, val_f1_macro, val_cohen_k, val_roc_auc, _, _ = evaluate_model(\n",
    "            model_obj, val_loader, criterion, device, num_classes\n",
    "        )\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        metrics_history.append({\n",
    "            'epoch': epoch + 1, 'train_loss': avg_train_loss, 'val_loss': avg_val_loss,\n",
    "            'val_accuracy': val_accuracy, 'val_f1_weighted': val_f1_w, \n",
    "            'val_f1_macro': val_f1_macro, 'val_cohen_kappa': val_cohen_k, 'val_roc_auc': val_roc_auc\n",
    "        })\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f\"Epoch {epoch+1} Summary | Time: {epoch_time:.2f}s\")\n",
    "        print(f\"  Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f} | Val F1 (w): {val_f1_w:.4f} | Val F1 (m): {val_f1_macro:.4f} | Val Kappa: {val_cohen_k:.4f} | Val AUC: {val_roc_auc:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_f1_w)\n",
    "\n",
    "        if val_f1_w > best_val_f1_weighted:\n",
    "            best_val_f1_weighted = val_f1_w\n",
    "            best_model_state = copy.deepcopy({k: v.cpu() for k, v in model_obj.state_dict().items()})\n",
    "            epochs_no_improve = 0\n",
    "            print(f\"  -> New best validation F1 (weighted): {best_val_f1_weighted:.4f}. Saving model state.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  Validation F1 (weighted) did not improve for {epochs_no_improve} epoch(s). Current best: {best_val_f1_weighted:.4f}\")\n",
    "\n",
    "\n",
    "        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "            \n",
    "        if device == torch.device(\"mps\"): torch.mps.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    total_fold_time = time.time() - total_fold_start_time\n",
    "    print(f\"\\nTraining finished for Fold {fold_num}. Total time: {total_fold_time:.2f}s. Best F1 (w) during training: {best_val_f1_weighted:.4f}\")\n",
    "    return best_model_state, train_losses, val_losses, metrics_history, best_val_f1_weighted\n",
    "\n",
    "if not PEFT_AVAILABLE:\n",
    "    print(\"PEFT library not available. Cannot proceed with LoRA fine-tuning. Exiting.\")\n",
    "elif df.empty or len(df) < NUM_FOLDS:\n",
    "    print(f\"DataFrame is empty or has insufficient data ({len(df)} samples) for {NUM_FOLDS}-Fold cross-validation. Exiting.\")\n",
    "else:\n",
    "    all_vh_sequences = df['VH'].tolist()\n",
    "    all_vl_sequences = df['VL'].tolist()\n",
    "    all_labels_list = df['label'].tolist()\n",
    "    overall_results_per_esm_model = []\n",
    "\n",
    "    for esm_model_name_hf in ESM2_MODEL_NAMES:\n",
    "        print(f\"\\n\\n===== Processing ESM Model: {esm_model_name_hf} with LoRA Fine-Tuning =====\")\n",
    "        \n",
    "        current_head_type = 'medium'\n",
    "        if \"8M\" in esm_model_name_hf: current_head_type = 'simple'\n",
    "        elif \"35M\" in esm_model_name_hf or \"150M\" in esm_model_name_hf: current_head_type = 'medium'\n",
    "        elif \"650M\" in esm_model_name_hf: current_head_type = 'deep'\n",
    "        print(f\"Using head type: {current_head_type} for {esm_model_name_hf}\")\n",
    "\n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(esm_model_name_hf)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load tokenizer for {esm_model_name_hf}. Error: {e}. Trying base esm2_t6_8M_UR50D tokenizer.\")\n",
    "            try:\n",
    "                tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "            except Exception as e_base:\n",
    "                print(f\"Could not load base ESM tokenizer. Error: {e_base}. Skipping this model.\")\n",
    "                overall_results_per_esm_model.append({'ESM Model': esm_model_name_hf, 'Error': f'Tokenizer load failed: {e_base}'})\n",
    "                continue\n",
    "        \n",
    "        full_dataset = AntibodyPsrDataset(all_vh_sequences, all_vl_sequences, all_labels_list, tokenizer, MAX_LENGTH)\n",
    "        if len(full_dataset) < NUM_FOLDS:\n",
    "            print(f\"Skipping {esm_model_name_hf}: Not enough samples ({len(full_dataset)}) for {NUM_FOLDS}-fold CV.\")\n",
    "            overall_results_per_esm_model.append({'ESM Model': esm_model_name_hf, 'Error': 'Insufficient samples for CV'})\n",
    "            continue\n",
    "\n",
    "        kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "        fold_results_current_esm = []\n",
    "        \n",
    "        print(f\"\\n--- Starting {NUM_FOLDS}-Fold Cross-Validation for {esm_model_name_hf} (LoRA) ---\")\n",
    "        cv_start_time = time.time()\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(full_dataset)))):\n",
    "            fold_num = fold + 1\n",
    "            print(f\"\\n==================== Fold {fold_num}/{NUM_FOLDS} ({esm_model_name_hf} LoRA) ====================\")\n",
    "            \n",
    "            if len(val_idx) == 0 or len(train_idx) == 0:\n",
    "                print(f\"Skipping Fold {fold_num} due to empty train/validation set. This is unexpected.\")\n",
    "                continue\n",
    "\n",
    "            train_sampler = SubsetRandomSampler(train_idx)\n",
    "            val_sampler = SubsetRandomSampler(val_idx)\n",
    "            \n",
    "            pin_mem = True if device.type == 'cuda' else False\n",
    "            train_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=0, pin_memory=pin_mem)\n",
    "            val_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, num_workers=0, pin_memory=pin_mem)\n",
    "            print(f\"Fold {fold_num}: Train samples = {len(train_idx)}, Validation samples = {len(val_idx)}\")\n",
    "\n",
    "            current_batch_size_to_check = BATCH_SIZE\n",
    "            if \"650M\" in esm_model_name_hf and current_batch_size_to_check > 1 and device == torch.device(\"mps\"):\n",
    "                print(f\"Warning: BATCH_SIZE {current_batch_size_to_check} for {esm_model_name_hf} (650M) on MPS with LoRA. Monitor memory.\")\n",
    "            elif \"150M\" in esm_model_name_hf and current_batch_size_to_check > 2 and device == torch.device(\"mps\"):\n",
    "                print(f\"Warning: BATCH_SIZE {current_batch_size_to_check} for {esm_model_name_hf} (150M) on MPS with LoRA. Monitor memory.\")\n",
    "\n",
    "            model = None\n",
    "            try:\n",
    "                model, optimizer, criterion, scheduler = initialize_model_and_optimizer(\n",
    "                    esm_model_name_hf, NUM_CLASSES, current_head_type, LEARNING_RATE, WEIGHT_DECAY, class_weights_tensor,\n",
    "                    LORA_R, LORA_ALPHA, LORA_DROPOUT, N_LAST_LAYERS\n",
    "                )\n",
    "            except Exception as model_init_e:\n",
    "                print(f\"Error during model initialization for {esm_model_name_hf}, Fold {fold_num}: {model_init_e}\")\n",
    "                fold_results_current_esm.append({\n",
    "                    'fold': fold_num, 'error': str(model_init_e), 'accuracy': np.nan, 'precision_w': np.nan, \n",
    "                    'recall_w': np.nan, 'f1_w': np.nan, 'f1_macro': np.nan, 'cohen_kappa': np.nan, \n",
    "                    'roc_auc': np.nan, 'best_val_metric_f1w': np.nan,\n",
    "                })\n",
    "                if model: del model\n",
    "                if device == torch.device(\"mps\"): torch.mps.empty_cache()\n",
    "                gc.collect()\n",
    "                continue\n",
    "\n",
    "            best_model_state, train_losses, val_losses, metrics_history, fold_best_f1_w_train = run_training_fold(\n",
    "                esm_model_name_hf, model, optimizer, criterion, scheduler, train_loader, val_loader, EPOCHS, device, NUM_CLASSES, fold_num\n",
    "            )\n",
    "            \n",
    "            if best_model_state:\n",
    "                model.to(device) \n",
    "                try:\n",
    "                    model.load_state_dict(best_model_state)\n",
    "                    print(\"\\nLoaded best model state from training for final evaluation on this fold.\")\n",
    "                except RuntimeError as e:\n",
    "                    print(f\"\\nError loading best model state: {e}. Evaluating with current model state.\")\n",
    "            else:\n",
    "                print(\"\\nWarning: No best model state saved (e.g., training too short or no improvement). Evaluating with the last model state.\")\n",
    "            \n",
    "            print(f\"Performing final evaluation for Fold {fold_num} ({esm_model_name_hf} LoRA)...\")\n",
    "            final_val_loss, final_accuracy, final_prec_w, final_recall_w, final_f1_w, final_f1_macro, final_cohen_k, final_roc_auc, fold_labels, fold_preds = evaluate_model(\n",
    "                model, val_loader, criterion, device, NUM_CLASSES\n",
    "            )\n",
    "            print(f\"\\nFold {fold_num} ({esm_model_name_hf} LoRA) Final Validation Metrics (using model with F1_w={fold_best_f1_w_train:.4f} from training):\")\n",
    "            print(f\"  Loss:           {final_val_loss:.4f}\")\n",
    "            print(f\"  Accuracy:       {final_accuracy:.4f}\")\n",
    "            print(f\"  Precision (w):  {final_prec_w:.4f}\")\n",
    "            print(f\"  Recall (w):     {final_recall_w:.4f}\")\n",
    "            print(f\"  F1 Score (w):   {final_f1_w:.4f} (This is the key eval metric for this fold's best model)\")\n",
    "            print(f\"  F1 Score (m):   {final_f1_macro:.4f}\")\n",
    "            print(f\"  Cohen's Kappa:  {final_cohen_k:.4f}\")\n",
    "            print(f\"  ROC AUC (w ovr):{final_roc_auc:.4f}\")\n",
    "            \n",
    "            fold_results_current_esm.append({\n",
    "                'fold': fold_num, 'accuracy': final_accuracy, 'precision_w': final_prec_w,\n",
    "                'recall_w': final_recall_w, 'f1_w': final_f1_w, 'f1_macro': final_f1_macro,\n",
    "                'cohen_kappa': final_cohen_k, 'roc_auc': final_roc_auc, \n",
    "                'best_val_metric_f1w_during_train': fold_best_f1_w_train,\n",
    "            })\n",
    "            \n",
    "            if metrics_history:\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.plot([m['epoch'] for m in metrics_history], [m['train_loss'] for m in metrics_history], label='Training Loss', marker='o')\n",
    "                plt.plot([m['epoch'] for m in metrics_history], [m['val_loss'] for m in metrics_history], label='Validation Loss', marker='x')\n",
    "                plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title(f'Fold {fold_num} ({esm_model_name_hf} LoRA) - Loss')\n",
    "                plt.legend(); plt.grid(True); plt.ylim(bottom=0)\n",
    "\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.plot([m['epoch'] for m in metrics_history], [m['val_f1_weighted'] for m in metrics_history], label='Val F1 (w)', marker='s')\n",
    "                plt.plot([m['epoch'] for m in metrics_history], [m['val_f1_macro'] for m in metrics_history], label='Val F1 (m)', marker='p')\n",
    "                valid_roc_auc_scores = [m['val_roc_auc'] for m in metrics_history if not np.isnan(m['val_roc_auc'])]\n",
    "                if valid_roc_auc_scores:\n",
    "                    epochs_with_valid_roc = [m['epoch'] for m in metrics_history if not np.isnan(m['val_roc_auc'])]\n",
    "                    plt.plot(epochs_with_valid_roc, valid_roc_auc_scores, label='Val ROC AUC', marker='^')\n",
    "                plt.plot([m['epoch'] for m in metrics_history], [m['val_accuracy'] for m in metrics_history], label='Val Accuracy', marker='.')\n",
    "                plt.xlabel('Epoch'); plt.ylabel('Metric Value'); plt.title(f'Fold {fold_num} ({esm_model_name_hf} LoRA) - Metrics')\n",
    "                plt.legend(); plt.grid(True); plt.ylim(0, 1.05)\n",
    "                plt.tight_layout(); plt.show()\n",
    "            else:\n",
    "                print(f\"No metrics history to plot for Fold {fold_num} (e.g. if training was skipped).\")\n",
    "\n",
    "            if len(fold_labels) > 0 and len(fold_preds) > 0:\n",
    "                try:\n",
    "                    cm = confusion_matrix(fold_labels, fold_preds, labels=list(range(NUM_CLASSES)))\n",
    "                    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[f'Class {i}' for i in range(NUM_CLASSES)])\n",
    "                    disp.plot(cmap=plt.cm.Blues)\n",
    "                    plt.title(f'Fold {fold_num} ({esm_model_name_hf} LoRA) - Confusion Matrix')\n",
    "                    plt.show()\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not display confusion matrix for Fold {fold_num}: {e}\")\n",
    "            else:\n",
    "                print(f\"Not enough data (labels/predictions) for confusion matrix in Fold {fold_num}.\")\n",
    "            \n",
    "            print(f\"Cleaning up Fold {fold_num} resources...\")\n",
    "            del model, optimizer, criterion, scheduler, train_loader, val_loader, train_sampler, val_sampler, best_model_state\n",
    "            if device == torch.device(\"mps\"): torch.mps.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        cv_end_time = time.time()\n",
    "        print(f\"\\n--- Cross-Validation Finished for {esm_model_name_hf} (LoRA) --- Total Time: {cv_end_time - cv_start_time:.2f}s ---\")\n",
    "        \n",
    "        results_df_current_esm = pd.DataFrame(fold_results_current_esm)\n",
    "        avg_metrics_dict = {'ESM Model': f\"{esm_model_name_hf} (LoRA)\", 'Error': None}\n",
    "        if not results_df_current_esm.empty and 'accuracy' in results_df_current_esm.columns and not results_df_current_esm['accuracy'].isnull().all():\n",
    "            print(f\"\\n--- Cross-Validation Summary for {esm_model_name_hf} (LoRA) ---\")\n",
    "            metric_cols_summary = ['fold', 'accuracy', 'f1_w', 'f1_macro', 'cohen_kappa', 'roc_auc', 'best_val_metric_f1w_during_train']\n",
    "            display_cols_summary = [col for col in metric_cols_summary if col in results_df_current_esm.columns]\n",
    "            print(results_df_current_esm[display_cols_summary].round(4).to_string(index=False))\n",
    "            \n",
    "            for metric in ['accuracy', 'f1_w', 'f1_macro', 'cohen_kappa', 'roc_auc']:\n",
    "                if metric in results_df_current_esm.columns:\n",
    "                    avg_metrics_dict[f'Avg {metric}'] = results_df_current_esm[metric].mean(skipna=True)\n",
    "                    avg_metrics_dict[f'Std {metric}'] = results_df_current_esm[metric].std(skipna=True)\n",
    "                else:\n",
    "                    avg_metrics_dict[f'Avg {metric}'] = np.nan\n",
    "                    avg_metrics_dict[f'Std {metric}'] = np.nan\n",
    "        else:\n",
    "            avg_metrics_dict['Error'] = 'No valid fold results to aggregate'\n",
    "\n",
    "        overall_results_per_esm_model.append(avg_metrics_dict)\n",
    "        print(\"\\nAverage Metrics Across Folds:\")\n",
    "        for key, val in avg_metrics_dict.items():\n",
    "            if key not in ['ESM Model', 'Error'] and \"Std\" not in key:\n",
    "                std_key = key.replace(\"Avg\", \"Std\")\n",
    "                std_val = avg_metrics_dict.get(std_key, np.nan)\n",
    "                if isinstance(val, (int, float)) and not np.isnan(val):\n",
    "                     print(f\"  {key:<35}: {val:.4f} +/- {std_val:.4f}\")\n",
    "                else:\n",
    "                     print(f\"  {key:<35}: N/A\")\n",
    "            elif key == 'Error' and val is not None:\n",
    "                print(f\"  Error: {val}\")\n",
    "\n",
    "    print(\"\\n\\n===== Overall Summary Across All ESM Models (LoRA Fine-Tuning) =====\")\n",
    "    summary_df = pd.DataFrame(overall_results_per_esm_model)\n",
    "    \n",
    "    cols_to_display_final = ['ESM Model', 'Error']\n",
    "    valid_results_exist_final = any(\n",
    "        r.get('Error') is None and \n",
    "        any(not pd.isna(v) for k, v in r.items() if k not in ['ESM Model', 'Error']) \n",
    "        for r in overall_results_per_esm_model\n",
    "    )\n",
    "\n",
    "    if valid_results_exist_final:\n",
    "        first_valid_result_final = next((r for r in overall_results_per_esm_model if r.get('Error') is None and any(not pd.isna(v) for k, v in r.items() if k not in ['ESM Model', 'Error'])), None)\n",
    "        if first_valid_result_final:\n",
    "            metric_avg_std_cols_final = [k for k in first_valid_result_final.keys() if k not in ['ESM Model', 'Error']]\n",
    "            cols_to_display_final.extend(metric_avg_std_cols_final)\n",
    "\n",
    "    summary_df_display_final = summary_df[[col for col in cols_to_display_final if col in summary_df.columns]]\n",
    "    \n",
    "    numeric_cols_final = summary_df_display_final.select_dtypes(include=np.number).columns\n",
    "    summary_df_display_final[numeric_cols_final] = summary_df_display_final[numeric_cols_final].round(4)\n",
    "    \n",
    "    print(summary_df_display_final.to_string(index=False))\n",
    "\n",
    "print(\"\\n--- Script Finished ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
